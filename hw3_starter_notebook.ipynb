{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Name: AllTheBest\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI: **pw2435**\n",
    "* Name: **Pingyuan Wang**\n",
    "\n",
    "### Team Member 2:\n",
    "* UNI:  **cz2431**\n",
    "* Name: **Chenchao Zang**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.abspath(os.path.join(\"data\",\"data.csv\"))) as file:\n",
    "    df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_label_feature(df):\n",
    "    # Get the Label\n",
    "    y = df['subscribed']\n",
    "    lb = preprocessing.LabelBinarizer(neg_label=-1, pos_label=1)\n",
    "    y = lb.fit_transform(y)\n",
    "    y = y.ravel()\n",
    "    # Drop duration columns\n",
    "    X = df.drop('duration', 1)\n",
    "    X = X.drop('credit_default', 1)\n",
    "    X = df.drop('subscribed', 1)\n",
    "    X = X.drop('euribor3m',1)\n",
    "    X = X.drop('emp_var_rate',1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing_holdout(holdout):\n",
    "    # Drop duration columns\n",
    "    holdout = holdout.drop('duration', 1)\n",
    "    holdout = holdout.drop('ID', 1) \n",
    "    holdout = holdout.drop('credit_default', 1)\n",
    "    holdout = holdout.drop('euribor3m',1)\n",
    "    holdout = holdout.drop('emp_var_rate',1)\n",
    "    return holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_label(X):\n",
    "    binarizer = preprocessing.Binarizer(threshold=999).fit(X['prev_days'])\n",
    "    X['prev_days'] = binarizer.transform(X['prev_days']).T\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_unknown(X):\n",
    "    for i in range(1,7):\n",
    "        X.iloc[:, i].replace(to_replace=\"unknown\", value=np.nan, inplace=True)\n",
    "        X.loc[:]['prev_days'].replace(to_replace=999, value=-1, inplace=True)\n",
    "    # Feature where NA = \"nonexistent\"\n",
    "    X.iloc[:, 13].replace(to_replace=\"nonexistent\", value=np.nan, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dummy(X_train):\n",
    "    dum_cat = ['job', 'marital_status','education',\n",
    "            'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "            'prev_outcomes']\n",
    "    num_col=['age', 'campaign','cons_price_idx', 'cons_conf_idx', \n",
    "         'nr_employed','prev_contacts','prev_days']\n",
    "    \n",
    "    x_train_dummy = pd.DataFrame()\n",
    "    for ele in (dum_cat):\n",
    "        x_train_dummy = pd.concat([x_train_dummy,pd.get_dummies(X_train[ele], prefix=ele)],axis = 1)\n",
    "    \n",
    "    x_num_train = X_train[num_col]\n",
    "    x_train_dummy = pd.concat([x_train_dummy,x_num_train],axis=1)\n",
    "    return x_train_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_label_feature(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/pandas/core/generic.py:3443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train = replace_unknown(X_train)\n",
    "X_train = get_dummy(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/pandas/core/generic.py:3443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_test = replace_unknown(X_test)\n",
    "X_test = get_dummy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24712, 52), (8238, 52))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76966767458053709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "lr = LogisticRegression(C = 100)\n",
    "np.mean(cross_val_score(lr,X_train,y_train,cv=skfold,scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75523898573809689"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "test_y = lr.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6388, -7690)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test),sum(lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = svm.SVC(probability=True)\n",
    "# clf.fit(X_train,y_train)\n",
    "# np.mean(cross_val_score(clf,X_train,y_train,cv=skfold,scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70839147481234355"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_y = clf.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.777,  0.793,  0.797,  0.805,  0.779])"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wclf = svm.SVC(kernel='linear', class_weight={1: 5},probability=True)\n",
    "# wclf.fit(X_train,y_train)\n",
    "# np.mean(cross_val_score(wclf,X_train,y_train,cv=skfold,scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951122265090127"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_y = wclf.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79184512249612737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(reg,X_train,y_train,cv=skfold,scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_y = reg.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75160846504823997"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet()\n",
    "enet.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(enet,X_train,y_train,cv=skfold,scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_y = enet.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78740579930836074"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "est = LDA()\n",
    "est.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(est,X_train,y_train,cv=skfold,scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78658051892464798"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = est.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_professional.course  job_technician            0.480725\n",
      "prev_contacts                  nr_employed               0.501015\n",
      "nr_employed                    prev_contacts             0.501015\n",
      "prev_contacts                  prev_days                 0.509249\n",
      "prev_days                      prev_contacts             0.509249\n",
      "prev_outcomes_success          prev_contacts             0.532966\n",
      "prev_contacts                  prev_outcomes_success     0.532966\n",
      "prev_outcomes_failure          prev_contacts             0.674285\n",
      "prev_contacts                  prev_outcomes_failure     0.674285\n",
      "marital_status_married         marital_status_single     0.773760\n",
      "marital_status_single          marital_status_married    0.773760\n",
      "prev_outcomes_success          prev_days                 0.781928\n",
      "prev_days                      prev_outcomes_success     0.781928\n",
      "nr_employed                    emp_var_rate              0.902315\n",
      "emp_var_rate                   nr_employed               0.902315\n",
      "loan_yes                       loan_no                   0.913339\n",
      "loan_no                        loan_yes                  0.913339\n",
      "housing_no                     housing_yes               0.951624\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchaozang/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:12: FutureWarning: order is deprecated, use sort_values(...)\n"
     ]
    }
   ],
   "source": [
    "# Look at correlations between features\n",
    "# import seaborn as sns\n",
    "# Get to the numeric columns by inversion            \n",
    "num_list = X_train.columns \n",
    "\n",
    "# Create Dataframe containing only numerical features\n",
    "df_num = X_train[num_list]\n",
    "df_num.astype(float).corr()\n",
    "\n",
    "c = df_num.astype(float).corr().abs()\n",
    "\n",
    "s = c.unstack()\n",
    "so = s.order(kind=\"quicksort\")\n",
    "# [2940:2968]\n",
    "print (so[2841:2859])\n",
    "# f, ax = plt.subplots(figsize=(11, 11))\n",
    "# plt.title('Pearson Correlation of features')\n",
    "\n",
    "# # Draw the heatmap using seaborn\n",
    "# sns.heatmap(df_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "As we see LDA indicates that there exists multicollinearity problem in our features, we decide to do a feature selection based on removing dependent features on the result of variance threshold. Basically remove features that has low variance. However, after we remove those features and retrain our model, all the performance (cross_val_score and test roc_auc) becomse worse. Thus, we decide just to keep those variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove collinear features\n",
    "# sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "# mmm=sel.fit(x_train_dummy)\n",
    "# new_x=mmm.transform(x_train_dummy)\n",
    "# xxx=mmm.transform(x_test_dummy)\n",
    "# cross_val_score(lda,new_x,y_train,cv=skfold)\n",
    "# #Results becomes worse after feature selection for all the following models.\n",
    "# lr.fit(new_x,y_train)\n",
    "# pred_prob=lr.predict_proba(xxx)[:,1]\n",
    "# roc_auc_score(y_test,pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randome Forest (Overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89264335225129376"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(rfc,X_train,y_train,cv=skfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74844308262770232"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = rfc.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89741822457930565"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(clf,X_train,y_train,cv=skfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78312690939313856"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = clf.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89867264639635669"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "np.mean(cross_val_score(clf,X_train,y_train,cv=skfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79175549803314105"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = clf.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection based on feature importance\n",
    "We tried feature selection based on feature importance, however, the result again becomes worse for all the models. Thus, we decide to keep all the features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try feature selection based on importance, the result becomse worse. From 77-72\n",
    "# rfc.fit(x_train_dummy,y_train)\n",
    "# imp=rfc.feature_importances_\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# model = SelectFromModel(rfc, prefit=True)\n",
    "# X_new = model.transform(x_train_dummy)\n",
    "# x_test_new=model.transform(x_test_dummy)\n",
    "# one_hot_new=model.transform(onehot_final)\n",
    "# rfc=RandomForestClassifier()\n",
    "# cross_val_score(rfc,X_new,y_train,cv=skfold)\n",
    "# rfc.fit(X_new,y_train)\n",
    "# pred_prob=rfc.predict_proba(x_test_new)[:,1]\n",
    "# roc_auc_score(y_test,pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "We also notice that the response variable is very imbalanced, thus we decide to resampling the data to retrain the model. We used undersampling and oversampling, however, the cross_val_score becomes better, but the public score board on Kaggle becomes much worse, the score around 0.5. Thus, we decide not do resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Under Sampling, however, the results becomes worse\n",
    "# rus=RandomUnderSampler()\n",
    "# aaa,bbb=rus.fit_sample(x_train_dummy,y_train)\n",
    "#Random Over Sampling, however, the results becomes worse\n",
    "# ros=RandomOverSampler()\n",
    "# aaa,bbb=ros.fit_sample(x_train_dummy,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# Training classifiers\n",
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = GradientBoostingClassifier()\n",
    "clf3 = svm.SVC(kernel='linear', class_weight={1: 5},probability=True)\n",
    "# eclf = VotingClassifier(estimators=[('adaboost', clf1), ('gdb', clf2), ('svc', clf3)], voting='soft', weights=[1,2,2])\n",
    "eclf = VotingClassifier(estimators=[('adaboost', clf1), ('gdb', clf2)], voting='soft', weights=[1,2])\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "clf3 = clf3.fit(X_train, y_train)\n",
    "eclf = eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78091499403136211"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = eclf.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hold_out = pd.read_csv('/Users/chenchaozang/Downloads/holdout.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Holdout\n",
    "# holdout = processing_holdout(hold_out)\n",
    "# holdout = replace_unknown(holdout)\n",
    "# holdout = get_dummy(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Write results to csv\n",
    "# res = eclf.predict_proba(holdout)[:,1]\n",
    "# final_result = pd.concat([hold_out['ID'],pd.DataFrame(res)], axis=1)\n",
    "# final_result.columns = [\"ID\",\"subscribed\"]\n",
    "# header = [\"ID\",\"subscribed\"]\n",
    "# final_result.to_csv(\"holdout_result.csv\", columns = header, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "def test_accuracy():  \n",
    "    assert roc_auc_score(y_test,test_y)> 0.78\n",
    "test_accuracy()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
